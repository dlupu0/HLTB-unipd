{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "KTj_MOZOmzfn"
   },
   "source": [
    "# HowLongToBeat RDF Creator\n",
    "\n",
    "We load the generated CSV files and we serialize all the data into ***turtle format  (TTL)*** relying on ***RDFLib*** Python library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "GPtFAXlZmzfp"
   },
   "source": [
    "## Setup\n",
    "\n",
    "We import all the necessary libraries and we set the paths to the input/output files. In particular, we create a TTL file for each type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JXZwhL0Bmzfp"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "\n",
    "# RDFLib knows about some namespaces, like XSD\n",
    "from rdflib.namespace import XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LrSYA9LWmzfq"
   },
   "outputs": [],
   "source": [
    "absPath = str(Path(os.path.abspath(os.getcwd())).absolute())\n",
    "datasetsPath = os.path.join(absPath, \"cleaned_datasets\")\n",
    "rawdatasetsPath = os.path.join(absPath, \"raw_datasets\")\n",
    "rdfPath = os.path.join(absPath, \"rdf\")\n",
    "\n",
    "# Create dataset directory if not exists\n",
    "if not os.path.exists(datasetsPath):\n",
    "    os.mkdir(datasetsPath)\n",
    "\n",
    "# Create RDF directory if not exists\n",
    "if not os.path.exists(rdfPath):\n",
    "    os.mkdir(rdfPath)\n",
    "\n",
    "# Setup datasets paths\n",
    "gamesPath = os.path.join(datasetsPath, \"games_cleaned.csv\")\n",
    "vgchartzPath = os.path.join(datasetsPath, \"vgchartz_cleaned.csv\")\n",
    "indiegamesdevelopersPath = os.path.join(datasetsPath, \"indiegamesdevelopers_cleaned_seriesExplode.csv\")\n",
    "platformsPath = os.path.join(datasetsPath,\"platforms.csv\" )\n",
    "videoGameDevelopersPath = os.path.join(datasetsPath, \"videogamesdevelopers_cleaned_seriesexplode.csv\" )\n",
    "\n",
    "# Countries-Regions path\n",
    "countriesRegionsPath = os.path.join(datasetsPath, \"countries-regions.csv\")\n",
    "\n",
    "# Setup Turtle paths\n",
    "genresTTLPath = os.path.join(rdfPath, \"genres.ttl\")\n",
    "gamesTTLPath = os.path.join(rdfPath, \"games.ttl\")\n",
    "companyTTLPath = os.path.join(rdfPath, \"company.ttl\")\n",
    "platformsTTLPath = os.path.join(rdfPath, \"platforms.ttl\")\n",
    "videoGameDevelopersTTLPath = os.path.join(rdfPath, \"videoGameDevelopers.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rOveR-Rrmzfr"
   },
   "outputs": [],
   "source": [
    "# Country Ontology\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "\n",
    "# HLTB Ontology\n",
    "HLTB = Namespace(\"http://www.semanticweb.org/enrico/ontologies/2022/10/HLTB-db2unipd#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VbjlMp7fmzfr"
   },
   "outputs": [],
   "source": [
    "def createGraph():\n",
    "    # Create the graph\n",
    "    g = Graph()\n",
    "\n",
    "    # Bind the namespaces to a prefix for more readable output\n",
    "    g.bind(\"xsd\", XSD)\n",
    "    g.bind(\"countries\", CNS)\n",
    "    g.bind(\"hltb\", HLTB)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "WJv6ArAbmzfr"
   },
   "source": [
    "## Serialization\n",
    "\n",
    "We serialize the data according to the following workflow:\n",
    "\n",
    "1. Load the CSV file and iterate through it\n",
    "2. Create a unique ID by ourself based on the name of the class.\n",
    "3. Add the node to the graph using the unique ID.\n",
    "4. Add all the data properties.\n",
    "5. Add all the object properties.\n",
    "6. Serialize the data and save them into a TTL file.\n",
    "\n",
    "### Games\n",
    "\n",
    "Now serializing the Game class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QmQMPeKimzfr"
   },
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "games = pd.read_csv(gamesPath, sep=\",\", index_col=\"title\")\n",
    "vgchartz = pd.read_csv(vgchartzPath, sep=\",\", index_col=\"title\")\n",
    "#indiegamesdevelopers = pd.read_csv(indiegamesdevelopersPath, sep=\",\", index_col=\"title\") Borowei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createGameID(title):\n",
    "    # Replace all special chars with \"-\"\n",
    "    gameID = \"\"\n",
    "    for char in title:\n",
    "        if char.isalnum():\n",
    "            gameID += char\n",
    "        elif len(gameID) > 0 and gameID[-1] != '-':\n",
    "            gameID += '-'\n",
    "    if len(gameID) > 0 and gameID[-1] == '-':\n",
    "        gameID = gameID[:-1]\n",
    "    #print(gameID.lower())\n",
    "    return gameID.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 35922 entries, 688(I) Hunter/Killer to Yooka-Laylee and the Impossible Lair\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        35922 non-null  int64  \n",
      " 1   id                35922 non-null  int64  \n",
      " 2   main_story        17324 non-null  float64\n",
      " 3   main_plus_extras  11631 non-null  float64\n",
      " 4   completionist     13107 non-null  float64\n",
      " 5   all_styles        21112 non-null  float64\n",
      " 6   coop              183 non-null    float64\n",
      " 7   versus            274 non-null    float64\n",
      " 8   type              1314 non-null   object \n",
      " 9   developers        34080 non-null  object \n",
      " 10  publishers        32754 non-null  object \n",
      " 11  platforms         24285 non-null  object \n",
      " 12  genres            32843 non-null  object \n",
      "dtypes: float64(6), int64(2), object(5)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the games\n",
    "games.info()\n",
    "for title, row in games.iterrows():\n",
    "    # Create gameID from its title\n",
    "    gameID = createGameID(title)\n",
    "\n",
    "    # Create the node to add to the Graph\n",
    "    Game = URIRef(HLTB[gameID])\n",
    "\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Game, RDF.type, HLTB.Game))\n",
    "\n",
    "    # Add the title of the game\n",
    "    g.add((Game, HLTB[\"title\"], Literal(title, datatype=XSD.string)))\n",
    "\n",
    "    # Add multiplayer focus\n",
    "    g.add((Game, HLTB[\"multiplayerFocus\"], Literal(pd.notnull(row[\"coop\"]) or pd.notnull(row[\"versus\"]), datatype=XSD.boolean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "O4OpE1JNmzft"
   },
   "source": [
    "## Missing all other data about games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BpR7w_vVmzft",
    "outputId": "4065b697-c57a-4aee-f351-45ece195b6b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved games TTL file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data in the Turtle format\n",
    "with open(gamesTTLPath, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))\n",
    "\n",
    "print(\"Saved games TTL file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Xq17uGMEmzft"
   },
   "source": [
    "### Genre\n",
    "\n",
    "Now serializing the Genre class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()\n",
    "# Load the CSV files in memory\n",
    "genres = pd.read_csv(gamesPath, sep=\",\", index_col=\"genres\")\n",
    "\n",
    "def setGenreID(genre):\n",
    "    genre = str(genre).replace(\"/\",\", \").replace(\"nan\",\"\")\n",
    "    genre=genre.split(\", \")\n",
    "    list=[]\n",
    "    for i in range(len(genre)):\n",
    "        list.append([])\n",
    "        list[i].append(genre[i])\n",
    "        list[i].append(genre[i].lower().replace(\"'\",\"\").replace(\" \", \"-\"))\n",
    "    return(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for genre, row in genres.iterrows():\n",
    "    allGenres = setGenreID(genre)\n",
    "    for iterator in allGenres:\n",
    "        if not (iterator[0] == \" \" or iterator[0] == \"\"):\n",
    "            Genre = URIRef(HLTB[iterator[1]])\n",
    "            #Add triples using store's add() method.\n",
    "            g.add((Genre, RDF.type, HLTB.Genre))\n",
    "            # Add the name of the genre\n",
    "            g.add((Genre, HLTB[\"name\"], Literal(iterator[0], datatype=XSD.string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save genre data in the Turtle format\n",
    "with open(genresTTLPath, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()\n",
    "# Load the CSV files in memory\n",
    "platforms = pd.read_csv(platformsPath, sep=\",\", index_col=\"Platform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setPlatformID(platform):\n",
    "    return(platform.lower().replace(\" \", \"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for platform, row in platforms.iterrows():\n",
    "    Platform = URIRef(HLTB[setPlatformID(platform)])\n",
    "    #Add triples using store's add() method.\n",
    "    g.add((Platform, RDF.type, HLTB.Platform))\n",
    "    # Add the name of the genre\n",
    "    g.add((Platform, HLTB[\"name\"], Literal(platform, datatype=XSD.string)))\n",
    "\n",
    "    #Add popularity if platform is popular\n",
    "    if(row[\"Popular\"] == True):\n",
    "        g.add((Platform, HLTB[\"popular\"], Literal(True, datatype=XSD.boolean)))\n",
    "\n",
    "    #Add release date if present\n",
    "    if pd.notna(row[\"Release date\"]):\n",
    "        time = datetime.combine(datetime.strptime(row[\"Release date\"], '%Y-%M-%d'), datetime.min.time())\n",
    "        g.add((Platform, HLTB[\"releaseDate\"], Literal(time,datatype=XSD.dateTime)))\n",
    "\n",
    "    #Add CPU information\n",
    "    if pd.notna(row[\"CPU\"]):\n",
    "        g.add((Platform, HLTB[\"cpu\"], Literal(row[\"CPU\"],datatype=XSD.string)))\n",
    "\n",
    "    #Add CPU bit information\n",
    "    if pd.notna(row[\"\\\"Bits\\\"\"]):\n",
    "        bits = row[\"\\\"Bits\\\"\"].split(\"-\")[0]\n",
    "        g.add((Platform, HLTB[\"bits\"], Literal(bits,datatype=XSD.int)))\n",
    "\n",
    "    #Add acronym information\n",
    "    if pd.notna(row[\"Acronym\"]):\n",
    "        g.add((Platform, HLTB[\"acronym\"], Literal(row[\"Acronym\"],datatype=XSD.string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save data in the Turtle format\n",
    "with open(platformsTTLPath, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVPWWFGcnDbO"
   },
   "source": [
    "Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()\n",
    "# Load the CSV files in memory\n",
    "indiegamesdevelopers = pd.read_csv(indiegamesdevelopersPath, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace space with -, lower case\n",
    "indiegamesdevelopers['companyID'] = indiegamesdevelopers['Developer'].replace(' ', '-', regex=True).str.lower()\n",
    "\n",
    "\n",
    "#indiegamesdevelopers.info()\n",
    "for index, row in indiegamesdevelopers.iterrows():\n",
    "  # Create the node to add to the Graph\n",
    "  Company = URIRef(HLTB[row['companyID']])\n",
    "\n",
    "  # Add triples using store's add() method.\n",
    "  g.add((Company, RDF.type, HLTB.Company))\n",
    "\n",
    "  # Add the Company\n",
    "  g.add((Company, HLTB['officialName'], Literal(row['Developer'], datatype=XSD.string)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video-game-evelopers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoGameDevelopers = pd.read_csv(videoGameDevelopersPath, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace space with -, lower case\n",
    "videoGameDevelopers['companyID'] = videoGameDevelopers['Developer'].replace(' ', '-', regex=True).str.lower()\n",
    "\n",
    "\n",
    "#indiegamesdevelopers.info()\n",
    "for index, row in videoGameDevelopers.iterrows():\n",
    "  # Create the node to add to the Graph\n",
    "  Company = URIRef(HLTB[row['companyID']])\n",
    "\n",
    "  # Add triples using store's add() method.\n",
    "  g.add((Company, RDF.type, HLTB.Company))\n",
    "\n",
    "  # Add the Company\n",
    "  g.add((Company, HLTB[\"indieDeveloper\"], Literal(row['Developer'], datatype=XSD.boolean)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved company TTL file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data in the Turtle format\n",
    "with open(companyTTLPath, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))\n",
    "\n",
    "print(\"Saved company TTL file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
