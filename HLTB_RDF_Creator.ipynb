{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "\n",
    "# RDFLib knows about some namespaces, like FOAF and XSD\n",
    "from rdflib.namespace import FOAF, XSD"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\Desktop\\DB2 Git\\HLTB-unipd\n",
      "C:\\Users\\Daniel\\Desktop\\DB2 Git\\HLTB-unipd\\cleaned_datasets\n",
      "C:\\Users\\Daniel\\Desktop\\DB2 Git\\HLTB-unipd\\rdf\n",
      "C:\\Users\\Daniel\\Desktop\\DB2 Git\\HLTB-unipd\\cleaned_datasets\\platforms.csv\n"
     ]
    }
   ],
   "source": [
    "absPath = str(Path(os.path.abspath(os.getcwd())).absolute())\n",
    "datasetsPath = os.path.join(absPath, \"cleaned_datasets\")\n",
    "rdfPath = os.path.join(absPath, \"rdf\")\n",
    "print(absPath)\n",
    "print(datasetsPath)\n",
    "print(rdfPath)\n",
    "\n",
    "games = os.path.join(datasetsPath, \"cleaned_games.csv\")\n",
    "platforms = os.path.join(datasetsPath, \"platforms.csv\")\n",
    "print(platforms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "# Country Ontology\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "\n",
    "# HLTB Ontology\n",
    "GA = Namespace(\"https://www.dei.unipd.it/game#\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##GENRE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "def createGraph():\n",
    "    # Create the graph\n",
    "    g = Graph()\n",
    "\n",
    "    # Bind the namespaces to a prefix for more readable output\n",
    "    g.bind(\"xsd\", XSD)\n",
    "    g.bind(\"countries\", CNS)\n",
    "    g.bind(\"ga\", GA)\n",
    "\n",
    "    return g"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()\n",
    "# Load the CSV files in memory\n",
    "genres = pd.read_csv(games, sep=\",\", index_col=\"genres\")\n",
    "genres.to_csv(\"prova.txt\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def setGenreID(genre):\n",
    "    genre = str(genre).replace(\"/\",\", \").replace(\"nan\",\"\")\n",
    "    genre=genre.split(\", \")\n",
    "    list=[]\n",
    "    for i in range(len(genre)):\n",
    "        list.append([])\n",
    "        list[i].append(genre[i])\n",
    "        list[i].append(genre[i].lower().replace(\"'\",\"\").replace(\" \", \"-\"))\n",
    "    return(list)\n",
    "\n",
    "aa=[]\n",
    "\n",
    "for genre, row in genres.iterrows():\n",
    "    allGenres = setGenreID(genre)\n",
    "    for iterator in allGenres:\n",
    "        aa.append(iterator[1])\n",
    "        if not (iterator[0] == \" \" or iterator[0] == \"\"):\n",
    "            Genre = URIRef(GA[iterator[1]])\n",
    "            #Add triples using store's add() method.\n",
    "            g.add((Genre, RDF.type, GA.Genre))\n",
    "            # Add the name of the genre\n",
    "            g.add((Genre, GA[\"name\"], Literal(iterator[0], datatype=XSD.string)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "# Save data in the Turtle format\n",
    "with open(\"prova.txt\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#PLATFORM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()\n",
    "# Load the CSV files in memory\n",
    "platforms = pd.read_csv(platforms, sep=\",\", index_col=\"Platform\")\n",
    "platforms.to_csv(\"prova.txt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "def setPlatformID(platform):\n",
    "    return(platform.lower().replace(\" \", \"-\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "for platform, row in platforms.iterrows():\n",
    "    Platform = URIRef(GA[setPlatformID(platform)])\n",
    "    #Add triples using store's add() method.\n",
    "    g.add((Platform, RDF.type, GA.Platform))\n",
    "    # Add the name of the genre\n",
    "    g.add((Platform, GA[\"name\"], Literal(platform, datatype=XSD.string)))\n",
    "\n",
    "    #Add popularity if platform is popular\n",
    "    if(row[\"Popular\"] == True):\n",
    "        g.add((Platform, GA[\"popular\"], Literal(True, datatype=XSD.boolean)))\n",
    "\n",
    "    #Add release date if present\n",
    "    if pd.notna(row[\"Release date\"]):\n",
    "        time = datetime.combine(datetime.strptime(row[\"Release date\"], '%Y-%M-%d'), datetime.min.time())\n",
    "        g.add((Platform, GA[\"releaseDate\"], Literal(time,datatype=XSD.dateTime)))\n",
    "\n",
    "    #Add CPU information\n",
    "    if pd.notna(row[\"CPU\"]):\n",
    "        g.add((Platform, GA[\"cpu\"], Literal(row[\"CPU\"],datatype=XSD.string)))\n",
    "\n",
    "    #Add CPU bit information\n",
    "    if pd.notna(row[\"\\\"Bits\\\"\"]):\n",
    "        bits = row[\"\\\"Bits\\\"\"].split(\"-\")[0]\n",
    "        g.add((Platform, GA[\"bits\"], Literal(bits,datatype=XSD.int)))\n",
    "\n",
    "    #Add acronym information\n",
    "    if pd.notna(row[\"Acronym\"]):\n",
    "        g.add((Platform, GA[\"acronym\"], Literal(row[\"Acronym\"],datatype=XSD.string)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "# Save data in the Turtle format\n",
    "with open(\"prova.txt\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
