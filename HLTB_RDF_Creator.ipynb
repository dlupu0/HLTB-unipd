{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HowLongToBeat RDF Creator\n",
    "\n",
    "We load the generated CSV files and we serialize all the data into ***turtle format  (TTL)*** relying on ***RDFLib*** Python library."
   ],
   "metadata": {
    "collapsed": false,
    "id": "KTj_MOZOmzfn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "We import all the necessary libraries and we set the paths to the input/output files. In particular, we create a TTL file for each type of data."
   ],
   "metadata": {
    "collapsed": false,
    "id": "GPtFAXlZmzfp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# RDFLib knows about some namespaces, like XSD\n",
    "from rdflib.namespace import XSD"
   ],
   "metadata": {
    "id": "JXZwhL0Bmzfp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "absPath = str(Path(os.path.abspath(os.getcwd())).absolute())\n",
    "datasetsPath = os.path.join(absPath, \"cleaned_datasets\")\n",
    "rawdatasetsPath = os.path.join(absPath, \"raw_datasets\")\n",
    "rdfPath = os.path.join(absPath, \"rdf\")\n",
    "\n",
    "# Create dataset directory if not exists\n",
    "if not os.path.exists(datasetsPath):\n",
    "    os.mkdir(datasetsPath)\n",
    "\n",
    "# Create RDF directory if not exists\n",
    "if not os.path.exists(rdfPath):\n",
    "    os.mkdir(rdfPath)\n",
    "\n",
    "# Setup datasets paths\n",
    "gamesPath = os.path.join(datasetsPath, \"games_cleaned.csv\")\n",
    "vgchartzPath = os.path.join(datasetsPath, \"vgchartz_cleaned.csv\")\n",
    "indiegamesdevelopersPath = os.path.join(datasetsPath, \"indiegamesdevelopers_cleaned_seriesExplode.csv\")\n",
    "platformsPath = os.path.join(datasetsPath, \"platforms.csv\")\n",
    "videoGameDevelopersPath = os.path.join(datasetsPath, \"videogamesdevelopers_cleaned_seriesexplode.csv\")\n",
    "\n",
    "# Countries-Regions path\n",
    "countriesRegionsPath = os.path.join(datasetsPath, \"countries-regions.csv\")\n",
    "\n",
    "# Setup Turtle paths\n",
    "genresTTLPath = os.path.join(rdfPath, \"genres.ttl\")\n",
    "gamesTTLPath = os.path.join(rdfPath, \"games.ttl\")\n",
    "companyTTLPath = os.path.join(rdfPath, \"company.ttl\")\n",
    "platformsTTLPath = os.path.join(rdfPath, \"platforms.ttl\")\n",
    "videoGameDevelopersTTLPath = os.path.join(rdfPath, \"videoGameDevelopers.ttl\")"
   ],
   "metadata": {
    "id": "LrSYA9LWmzfq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Country Ontology\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "\n",
    "# HLTB Ontology\n",
    "HLTB = Namespace(\"http://www.semanticweb.org/enrico/ontologies/2022/10/HLTB-db2unipd#\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def createGraph():\n",
    "    # Create the graph\n",
    "    g = Graph()\n",
    "\n",
    "    # Bind the namespaces to a prefix for more readable output\n",
    "    g.bind(\"xsd\", XSD)\n",
    "    g.bind(\"countries\", CNS)\n",
    "    g.bind(\"hltb\", HLTB)\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "#create game URI\n",
    "def createGameID(title):\n",
    "    # Replace all special chars with \"-\"\n",
    "    gameID = \"\"\n",
    "    for char in title:\n",
    "        if char.isalnum():\n",
    "            gameID += char\n",
    "        elif len(gameID) > 0 and gameID[-1] != '-':\n",
    "            gameID += '-'\n",
    "    if len(gameID) > 0 and gameID[-1] == '-':\n",
    "        gameID = gameID[:-1]\n",
    "    #print(gameID.lower())\n",
    "    return gameID.lower()\n",
    "\n",
    "\n",
    "#Create genre URI\n",
    "def setGenreID(genre):  ##first half is the original genres, second half are processed and lowercase\n",
    "    genre = str(genre).replace(\"/\", \", \").replace(\"nan\", \"\")\n",
    "    genre = genre.split(\", \")\n",
    "    list = []\n",
    "    for i in range(len(genre)):\n",
    "        list.append([])\n",
    "        list[i].append(genre[i])\n",
    "        list[i].append(genre[i].lower().replace(\"'\", \"\").replace(\" \", \"-\"))\n",
    "    return (list)\n",
    "\n",
    "\n",
    "def setPlatformID(platform):\n",
    "    return platform.lower().replace(\" \", \"-\")\n",
    "\n",
    "\n",
    "def setDeveloperID(developer):\n",
    "    return developer.replace(' ', '-', regex=True).str.lower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Serialization\n",
    "\n",
    "We serialize the data according to the following workflow:\n",
    "\n",
    "1. Load the CSV file and iterate through it\n",
    "2. Create a unique ID by ourself based on the name of the class.\n",
    "3. Add the node to the graph using the unique ID.\n",
    "4. Add all the data properties.\n",
    "5. Add all the object properties.\n",
    "6. Serialize the data and save them into a TTL file.\n",
    "\n",
    "### Games\n",
    "\n",
    "Now serializing the Game class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "games = pd.read_csv(gamesPath, sep=\",\", index_col=\"title\")\n",
    "vgchartz = pd.read_csv(vgchartzPath, sep=\",\", index_col=\"title\")\n",
    "#indiegamesdevelopers = pd.read_csv(indiegamesdevelopersPath, sep=\",\", index_col=\"title\") Borowei\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Iterate over the games\n",
    "for title, row in games.iterrows():\n",
    "    # Create gameID from its title\n",
    "    gameID = createGameID(title)\n",
    "\n",
    "    # Create the node to add to the Graph\n",
    "    Game = URIRef(HLTB[gameID])\n",
    "\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Game, RDF.type, HLTB.Game))\n",
    "\n",
    "    # Add the title of the game\n",
    "    g.add((Game, HLTB[\"officialName\"], Literal(title, datatype=XSD.string)))\n",
    "\n",
    "    # Add multiplayer focus\n",
    "    g.add((Game, HLTB[\"multiplayerFocus\"],\n",
    "           Literal(pd.notnull(row[\"coop\"]) or pd.notnull(row[\"versus\"]), datatype=XSD.boolean)))\n",
    "\n",
    "    #Add hltb id\n",
    "    g.add((Game, HLTB[\"id\"], Literal(row[\"id\"], datatype=XSD.int)))\n",
    "\n",
    "    #Add hasGenre object property\n",
    "    for genreList in setGenreID(row[\"genres\"]):\n",
    "        for genre in genreList[:len(genreList) // 2]:\n",
    "            if (pd.notnull(genre) and genre != ''):\n",
    "                g.add((Game, HLTB[\"hasGenre\"], Literal(genre, datatype=XSD.string)))\n",
    "\n",
    "    #Add platform availability\n",
    "    if pd.notna(row[\"platforms\"]):\n",
    "        for platform in row[\"platforms\"].split(\", \"):\n",
    "            g.add((Game, HLTB[\"releasedOn\"], Literal(setPlatformID(platform), datatype=XSD.string)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved games TTL file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data in the Turtle format\n",
    "with open(gamesTTLPath, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))\n",
    "\n",
    "print(\"Saved games TTL file.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Genre\n",
    "\n",
    "Now serializing the Genre class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()\n",
    "# Load the CSV files in memory\n",
    "genres = pd.read_csv(gamesPath, sep=\",\", index_col=\"genres\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for genre, row in genres.iterrows():\n",
    "    allGenres = setGenreID(genre)\n",
    "    for iterator in allGenres:\n",
    "        if not (iterator[0] == \" \" or iterator[0] == \"\"):\n",
    "            Genre = URIRef(HLTB[iterator[1]])\n",
    "            #Add triples using store's add() method.\n",
    "            g.add((Genre, RDF.type, HLTB.Genre))\n",
    "            # Add the name of the genre\n",
    "            g.add((Genre, HLTB[\"name\"], Literal(iterator[0], datatype=XSD.string)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Save genre data in the Turtle format\n",
    "with open(genresTTLPath, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Platforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()\n",
    "# Load the CSV files in memory\n",
    "platforms = pd.read_csv(platformsPath, sep=\",\", index_col=\"Platform\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "for platform, row in platforms.iterrows():\n",
    "    Platform = URIRef(HLTB[setPlatformID(platform)])\n",
    "    #Add triples using store's add() method.\n",
    "    g.add((Platform, RDF.type, HLTB.Platform))\n",
    "    # Add the name of the genre\n",
    "    g.add((Platform, HLTB[\"name\"], Literal(platform, datatype=XSD.string)))\n",
    "\n",
    "    #Add popularity if platform is popular\n",
    "    if row[\"Popular\"]:\n",
    "        g.add((Platform, HLTB[\"popular\"], Literal(True, datatype=XSD.boolean)))\n",
    "\n",
    "    #Add release date if present\n",
    "    if pd.notna(row[\"Release date\"]):\n",
    "        time = datetime.combine(datetime.strptime(row[\"Release date\"], '%Y-%M-%d'), datetime.min.time())\n",
    "        g.add((Platform, HLTB[\"releaseDate\"], Literal(time, datatype=XSD.dateTime)))\n",
    "\n",
    "    #Add CPU information\n",
    "    if pd.notna(row[\"CPU\"]):\n",
    "        g.add((Platform, HLTB[\"cpu\"], Literal(row[\"CPU\"], datatype=XSD.string)))\n",
    "\n",
    "    #Add CPU bit information\n",
    "    if pd.notna(row[\"\\\"Bits\\\"\"]):\n",
    "        bits = row[\"\\\"Bits\\\"\"].split(\"-\")[0]\n",
    "        g.add((Platform, HLTB[\"bits\"], Literal(bits, datatype=XSD.int)))\n",
    "\n",
    "    #Add acronym information\n",
    "    if pd.notna(row[\"Acronym\"]):\n",
    "        g.add((Platform, HLTB[\"acronym\"], Literal(row[\"Acronym\"], datatype=XSD.string)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Save data in the Turtle format\n",
    "with open(platformsTTLPath, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Company"
   ],
   "metadata": {
    "id": "BVPWWFGcnDbO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Create Graph\n",
    "g = createGraph()\n",
    "# Load the CSV files in memory\n",
    "indiegamesdevelopers = pd.read_csv(indiegamesdevelopersPath, sep=\",\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#replace space with -, lower case\n",
    "indiegamesdevelopers['companyID'] = setDeveloperID(indiegamesdevelopers['Developer'])\n",
    "\n",
    "#indiegamesdevelopers.info()\n",
    "for index, row in indiegamesdevelopers.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    Company = URIRef(HLTB[row['companyID']])\n",
    "\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Company, RDF.type, HLTB.Company))\n",
    "\n",
    "    # Add the Company\n",
    "    g.add((Company, HLTB[\"indieDeveloper\"], Literal(pd.notnull(row['Developer']), datatype=XSD.boolean)))\n",
    "    g.add((Company, HLTB['officialName'], Literal(row['Developer'], datatype=XSD.string)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### video-game-evelopers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "videoGameDevelopers = pd.read_csv(videoGameDevelopersPath, sep=\",\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#replace space with -, lower case\n",
    "videoGameDevelopers['companyID'] = setDeveloperID(videoGameDevelopers['Developer'])\n",
    "\n",
    "#indiegamesdevelopers.info()\n",
    "for index, row in videoGameDevelopers.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    Company = URIRef(HLTB[row['companyID']])\n",
    "\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Company, RDF.type, HLTB.Company))\n",
    "\n",
    "    # Add the Company\n",
    "    g.add((Company, HLTB['officialName'], Literal(row['Developer'], datatype=XSD.string)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the data in the Turtle format\n",
    "with open(companyTTLPath, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))\n",
    "\n",
    "print(\"Saved company TTL file.\")"
   ],
   "metadata": {
    "id": "dbKlh6J9ozNy"
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved company TTL file.\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
